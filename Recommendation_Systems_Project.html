<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>d76a4636071c4d888910592428fbfecd</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="pXQzH0nC5JtP">
<h1 id="project-amazon-product-recommendation-system"><strong>Project:
Amazon Product Recommendation System</strong></h1>
<h1 id="marks-40"><strong>Marks: 40</strong></h1>
<p>Welcome to the project on Recommendation Systems. We will work with
the Amazon product reviews dataset for this project. The dataset
contains ratings of different electronic products. It does not include
information about the products or reviews to avoid bias while building
the model.</p>
<hr />
<h2 id="-context">## <strong>Context:</strong></h2>
<p>Today, information is growing exponentially with volume, velocity and
variety throughout the globe. This has lead to information overload, and
too many choices for the consumer of any business. It represents a real
dilemma for these consumers and they often turn to denial. Recommender
Systems are one of the best tools that help recommending products to
consumers while they are browsing online. Providing personalized
recommendations which is most relevant for the user is what's most
likely to keep them engaged and help business.</p>
<p>E-commerce websites like Amazon, Walmart, Target and Etsy use
different recommendation models to provide personalized suggestions to
different users. These companies spend millions of dollars to come up
with algorithmic techniques that can provide personalized
recommendations to their users.</p>
<p>Amazon, for example, is well-known for its accurate selection of
recommendations in its online site. Amazon's recommendation system is
capable of intelligently analyzing and predicting customers' shopping
preferences in order to offer them a list of recommended products.
Amazon's recommendation algorithm is therefore a key element in using AI
to improve the personalization of its website. For example, one of the
baseline recommendation models that Amazon uses is item-to-item
collaborative filtering, which scales to massive data sets and produces
high-quality recommendations in real-time.</p>
<hr />
<h2 id="-objective">## <strong>Objective:</strong></h2>
<p>You are a Data Science Manager at Amazon, and have been given the
task of building a recommendation system to recommend products to
customers based on their previous ratings for other products. You have a
collection of labeled data of Amazon reviews of products. The goal is to
extract meaningful insights from the data and build a recommendation
system that helps in recommending products to online consumers.</p>
<hr />
<h2 id="-dataset">## <strong>Dataset:</strong></h2>
<p>The Amazon dataset contains the following attributes:</p>
<ul>
<li><strong>userId:</strong> Every user identified with a unique id</li>
<li><strong>productId:</strong> Every product identified with a unique
id</li>
<li><strong>Rating:</strong> The rating of the corresponding product by
the corresponding user</li>
<li><strong>timestamp:</strong> Time of the rating. We <strong>will not
use this column</strong> to solve the current problem</li>
</ul>
</div>
<div class="cell markdown" id="nmdPxJ2Q7W7p">
<p><strong>Note:</strong> The code has some user defined functions that
will be usefull while making recommendations and measure model
performance, you can use these functions or can create your own
functions.</p>
</div>
<div class="cell markdown" id="UoRfgjS2yekq">
<p>Sometimes, the installation of the surprise library, which is used to
build recommendation systems, faces issues in Jupyter. To avoid any
issues, it is advised to use <strong>Google Colab</strong> for this
project.</p>
<p>Let's start by mounting the Google drive on Colab.</p>
</div>
<div class="cell code" data-execution_count="2"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="GZ0YAszcT4zK" data-outputId="eb1a6a22-53ed-43f1-c945-099763f8f984">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">&#39;/content/drive&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mounted at /content/drive
</code></pre>
</div>
</div>
<div class="cell markdown" id="0Ibk07-Cyekt">
<p><strong>Installing surprise library</strong></p>
</div>
<div class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="05HQoiZYlsbB" data-outputId="e461096c-5086-482d-f05f-86e53984510c">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install scikit<span class="op">-</span>surprise</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Collecting scikit-surprise
  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 772.0/772.0 kB 11.6 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: joblib&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.23.5)
Requirement already satisfied: scipy&gt;=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.2)
Building wheels for collected packages: scikit-surprise
  Building wheel for scikit-surprise (setup.py) ... e=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3156231 sha256=07b0710149d79995cafdd0085b31ed39d287ff3daf9d99a3bcd7da8fedd6f81c
  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445
Successfully built scikit-surprise
Installing collected packages: scikit-surprise
Successfully installed scikit-surprise-1.1.3
</code></pre>
</div>
</div>
<section
id="importing-the-necessary-libraries-and-overview-of-the-dataset"
class="cell markdown" id="7fIt4jcFIm76">
<h2><strong>Importing the necessary libraries and overview of the
dataset</strong></h2>
</section>
<div class="cell code" data-execution_count="4" id="jzu2P-TT5JtP">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> Dataset, Reader</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> KNNWithMeans, accuracy</span></code></pre></div>
</div>
<section id="loading-the-data" class="cell markdown" id="NrXYJAv95JtP">
<h3><strong>Loading the data</strong></h3>
<ul>
<li>Import the Dataset</li>
<li>Add column names ['user_id', 'prod_id', 'rating', 'timestamp']</li>
<li>Drop the column timestamp</li>
<li>Copy the data to another DataFrame called <strong>df</strong></li>
</ul>
</section>
<div class="cell code" data-execution_count="5" id="JGb-Hk1B5JtP">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/DS+ML/R_Systems/ratings_Electronics.csv&quot;</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(file_path)</span></code></pre></div>
</div>
<div class="cell markdown" id="OVQnSG5g_9uX">
<p><strong>As this dataset is very large and has 7,824,482 observations,
it is not computationally possible to build a model using this.
Moreover, many users have only rated a few products and also some
products are rated by very few users. Hence, we can reduce the dataset
by considering certain logical assumptions.</strong></p>
<p>Here, we will be taking users who have given at least 50 ratings, and
the products that have at least 5 ratings, as when we shop online we
prefer to have some number of ratings of a product.</p>
</div>
<div class="cell code" data-execution_count="7" id="4yt9W7Q32EQQ">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the column containing the users</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>users <span class="op">=</span> df.iloc[:, <span class="dv">0</span>]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary from users to their number of ratings</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>ratings_count <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> user <span class="kw">in</span> users:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If we already have the user, just add 1 to their rating count</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> user <span class="kw">in</span> ratings_count:</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        ratings_count[user] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Otherwise, set their rating count to 1</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        ratings_count[user] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="8" id="19XB60dq2EQR">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We want our users to have at least 50 ratings to be considered</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>RATINGS_CUTOFF <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>remove_users <span class="op">=</span> []</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> user, num_ratings <span class="kw">in</span> ratings_count.items():</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_ratings <span class="op">&lt;</span> RATINGS_CUTOFF:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        remove_users.append(user)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.loc[ <span class="op">~</span> df.iloc[:, <span class="dv">0</span>].isin(remove_users)]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="9" id="33UzK1D82EQS">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the column containing the products</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>prods <span class="op">=</span> df.iloc[:, <span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary from products to their number of ratings</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ratings_count <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prod <span class="kw">in</span> prods:</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If we already have the product, just add 1 to its rating count</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prod <span class="kw">in</span> ratings_count:</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        ratings_count[prod] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Otherwise, set their rating count to 1</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        ratings_count[prod] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="10" id="u6YE-lUp2EQT">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We want our item to have at least 5 ratings to be considered</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>RATINGS_CUTOFF <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>remove_users <span class="op">=</span> []</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> user, num_ratings <span class="kw">in</span> ratings_count.items():</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_ratings <span class="op">&lt;</span> RATINGS_CUTOFF:</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        remove_users.append(user)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>df_final <span class="op">=</span> df.loc[<span class="op">~</span> df.iloc[:, <span class="dv">1</span>].isin(remove_users)]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="aL1JZ00o5JtQ" data-outputId="c9f7bf5d-1150-48ae-c1dd-b8ab531999c0">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a few rows of the imported dataset</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df_final.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="11">

  <div id="df-87ba5ffc-708f-48f5-9ab2-7feffd7b39df" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AKM1MP6P0OYPR</th>
      <th>0132793040</th>
      <th>5.0</th>
      <th>1365811200</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1309</th>
      <td>A3LDPF5FMB782Z</td>
      <td>1400501466</td>
      <td>5.0</td>
      <td>1336003200</td>
    </tr>
    <tr>
      <th>1321</th>
      <td>A1A5KUIIIHFF4U</td>
      <td>1400501466</td>
      <td>1.0</td>
      <td>1332547200</td>
    </tr>
    <tr>
      <th>1334</th>
      <td>A2XIOXRRYX0KZY</td>
      <td>1400501466</td>
      <td>3.0</td>
      <td>1371686400</td>
    </tr>
    <tr>
      <th>1450</th>
      <td>AW3LX47IHPFRL</td>
      <td>1400501466</td>
      <td>5.0</td>
      <td>1339804800</td>
    </tr>
    <tr>
      <th>1455</th>
      <td>A1E3OB6QMBKRYZ</td>
      <td>1400501466</td>
      <td>1.0</td>
      <td>1350086400</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-87ba5ffc-708f-48f5-9ab2-7feffd7b39df')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-87ba5ffc-708f-48f5-9ab2-7feffd7b39df button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-87ba5ffc-708f-48f5-9ab2-7feffd7b39df');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-ded09ecb-a852-4bc6-998f-a19e17a9d725">
  <button class="colab-df-quickchart" onclick="quickchart('df-ded09ecb-a852-4bc6-998f-a19e17a9d725')"
            title="Suggest charts."
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-ded09ecb-a852-4bc6-998f-a19e17a9d725 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>

</div>
</div>
<section id="exploratory-data-analysis" class="cell markdown"
id="GuPoy_XfxhXZ">
<h2><strong>Exploratory Data Analysis</strong></h2>
</section>
<section id="shape-of-the-data" class="cell markdown" id="s0d0bWeG-sVB">
<h3><strong>Shape of the data</strong></h3>
</section>
<section
id="check-the-number-of-rows-and-columns-and-provide-observations"
class="cell markdown" id="qyBVTRDTyek0">
<h3><strong>Check the number of rows and columns and provide
observations.</strong></h3>
</section>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="fJ4eQKaY5JtQ" data-outputId="2d87c3b8-3aeb-4cf3-b93c-e58b76b8487e">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the number of rows and columns and provide observations</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>num_rows, num_columns <span class="op">=</span> df_final.shape</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;The dataframe has </span><span class="sc">{</span>num_rows<span class="sc">}</span><span class="ss"> rows and </span><span class="sc">{</span>num_columns<span class="sc">}</span><span class="ss"> columns.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The dataframe has 65290 rows and 4 columns.
</code></pre>
</div>
</div>
<div class="cell markdown" id="Slp-fgWQ-sVD">
<p><strong>Write your observations here:</strong></p>
<p>The data now only has 65,290 rows instead of the initial 7,824,482.
This means that we have substantially reduced the data, meaning we will
have a much more focused analysis. The data structure still has 4
columns keeping the data simple. Now we will have be able to train the
model more effecienctly and our EDA is more feasible. A downside to this
reduction is that we have created potential bias as our data now only
consists of users who rate more frequently and products that have more
ratings.</p>
</div>
<section id="data-types" class="cell markdown" id="lAMWm0nC-sVF">
<h3><strong>Data types</strong></h3>
</section>
<div class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="SVrgMkye5JtQ" data-outputId="67e7cf37-aa62-4c0a-9397-929114b4e02a">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check Data types and provide observations</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_final.dtypes)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>AKM1MP6P0OYPR     object
0132793040        object
5.0              float64
1365811200         int64
dtype: object
</code></pre>
</div>
</div>
<div class="cell markdown" id="z4fOE02D-sVF">
<p><strong>Write your observations here:</strong></p>
<p>The dataset columns shows the user and product IDs as object types,
this tells us that they are alphanumeric strings. The ratings are shown
as type float64, whilst the timestamps are stored as Unix timestamps
int64. The column names are not named and unclear, so renaming them for
clarity might be beneficial.</p>
</div>
<section id="checking-for-missing-values" class="cell markdown"
id="lTMpOROT-sVG">
<h3><strong>Checking for missing values</strong></h3>
</section>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="vt-VEjMA5JtQ" data-outputId="648b4266-a012-43b0-c519-55e3995f677f">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values present and provide observations</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>missing_values <span class="op">=</span> df_final.isnull().<span class="bu">sum</span>()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_values)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>AKM1MP6P0OYPR    0
0132793040       0
5.0              0
1365811200       0
dtype: int64
</code></pre>
</div>
</div>
<div class="cell markdown" id="qMWuBNhI5JtR">
<p><strong>Write your observations here:</strong></p>
<p>The dataset has no missing values. This means that the data
collection was thorough and no imputation or cleaning methods are
required to handle nulls.</p>
</div>
<section id="summary-statistics" class="cell markdown"
id="wETrCg48-sVG">
<h3><strong>Summary Statistics</strong></h3>
</section>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="tYm30MXR5JtR" data-outputId="66063587-b838-4ac5-b23b-d0a7fc705e79">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary statistics of &#39;rating&#39; variable and provide observations</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>rating_stats <span class="op">=</span> df_final[<span class="st">&#39;5.0&#39;</span>].describe()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rating_stats)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>count    65290.000000
mean         4.294808
std          0.988915
min          1.000000
25%          4.000000
50%          5.000000
75%          5.000000
max          5.000000
Name: 5.0, dtype: float64
</code></pre>
</div>
</div>
<div class="cell markdown" id="VqW50EIJxhXc">
<p><strong>Write your observations here:</strong></p>
<p>Central tendency: Average rating is 4.29 which is pretty high on a
scale that goes up to 5. Meaning the majority of the products are liked
by the customers.</p>
<p>Dispersion: The standard deviation is 0.989, suggesting that the
ratings deviate by less that a full point. Meaning they are relatively
concentrated around the mean.</p>
<p>Range: ratings range from 1-5 meaning that some achieved the lowest
score and some received highest.</p>
<p>Distribution: 50% of the ratings are 5, meaning half the dataset have
products with perfect ratings. 75% of the dataset scored 5 or below,
once again telling us the scores are quite high for the products. 25%
are 4 or below, telling us that most the customers are satisfied with
the products.</p>
</div>
<section id="checking-the-rating-distribution" class="cell markdown"
id="ywyFrZIf5JtR">
<h3><strong>Checking the rating distribution</strong></h3>
</section>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:568}"
id="QbqhbEVe-sVH" data-outputId="6be5d19e-4810-4fa4-edad-502b65e63bfc">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the bar plot and provide observations</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the distribution of ratings</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>rating_distribution <span class="op">=</span> df_final[<span class="st">&#39;5.0&#39;</span>].value_counts().sort_index()</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the distribution</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>rating_distribution.index, y<span class="op">=</span>rating_distribution.values, alpha<span class="op">=</span><span class="fl">0.8</span>, palette<span class="op">=</span><span class="st">&quot;viridis&quot;</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Distribution of Ratings&#39;</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Number of Occurrences&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Rating Value&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_ba2b086bbe394df08800fe15b87a6853/dddbe2cd0c785a93e4625a26f51308f01a3bd0d0.png" /></p>
</div>
</div>
<div class="cell markdown" id="t0jONrQv-sVH">
<p><strong>Write your observations here:</strong></p>
<p>Most frequent rating is the score of 5. The least frequent is 1.
Indicating that most of the ratings are really high. The ratings also
trend upwards, meaning that users tend to give higher ratings</p>
</div>
<section
id="checking-the-number-of-unique-users-and-items-in-the-dataset"
class="cell markdown" id="HefpLdLJxhXd">
<h3><strong>Checking the number of unique users and items in the
dataset</strong></h3>
</section>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="NbSom7195JtR" data-outputId="608fa47d-779e-47de-a311-4aa6e784fa0b">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of total rows in the data and number of unique user id and product id in the data</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of unique users</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>unique_users <span class="op">=</span> df_final.iloc[:, <span class="dv">0</span>].nunique()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of unique products</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>unique_products <span class="op">=</span> df_final.iloc[:, <span class="dv">1</span>].nunique()</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Total rows in the dataset</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>total_rows <span class="op">=</span> df_final.shape[<span class="dv">0</span>]</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total rows in the dataset: </span><span class="sc">{</span>total_rows<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of unique users: </span><span class="sc">{</span>unique_users<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of unique products: </span><span class="sc">{</span>unique_products<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total rows in the dataset: 65290
Number of unique users: 1540
Number of unique products: 5689
</code></pre>
</div>
</div>
<div class="cell markdown" id="Qwgz6CUt-sVI">
<p><strong>Write your observations here:</strong></p>
<p>On average, each user has given a rating to 65290/1540 = 42 products.
This means that our filtering worked as we selected users who rated
atleast 50 products.</p>
<p>On average, each product has received a rating from 65290/5689 = 11.5
users. This tells us that there must be some popular products which
received a lot of ratings and other products which received none.</p>
</div>
<section id="users-with-the-most-number-of-ratings"
class="cell markdown" id="RfDnhSS4-sVI">
<h3><strong>Users with the most number of ratings</strong></h3>
</section>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="n7MX452q5JtR" data-outputId="2d92e546-7fc1-4ffc-c7a2-ece707324a3b">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Top 10 users based on the number of ratings</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>top_users <span class="op">=</span> df_final.iloc[:, <span class="dv">0</span>].value_counts().head(<span class="dv">10</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_users)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>ADLVFFE4VBT8      295
A3OXHLG6DIBRW8    230
A1ODOGXEYECQQ8    217
A36K2N527TXXJN    212
A25C2M3QF9G7OQ    203
A680RUE1FDO8B     196
A1UQBFCERIP7VJ    193
A22CW0ZHY3NJH8    193
AWPODHOB4GFWL     184
AGVWTYW0ULXHT     179
Name: AKM1MP6P0OYPR, dtype: int64
</code></pre>
</div>
</div>
<div class="cell markdown" id="1X2w_jt9-sVI">
<p><strong>Write your observations here:</strong></p>
<p>The top user is really active given he submitted nearly 300 ratings.
The distrubution amongst these users is relatively high with the lowest
amount of ratings being 179 and the highest 295. These users can hugely
influence the reccomendation system as they provide a broader range of
feedback for many products.</p>
</div>
<div class="cell markdown" id="EnYTx-Ol-sVg">
<p><strong>Now that we have explored and prepared the data, let's build
the first recommendation system.</strong></p>
</div>
<section id="model-1-rank-based-recommendation-system"
class="cell markdown" id="6xYGrGVy5JtS">
<h2><strong>Model 1: Rank Based Recommendation System</strong></h2>
</section>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="yxZTj1UPxhXh" data-outputId="bd527544-9678-4061-fad6-905f8abf84a1"
data-scrolled="true">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average rating for each product</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>average_ratings <span class="op">=</span> df_final.groupby(df_final.columns[<span class="dv">1</span>])[<span class="st">&#39;5.0&#39;</span>].mean()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the count of ratings for each product</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>count_ratings <span class="op">=</span> df_final.groupby(df_final.columns[<span class="dv">1</span>])[<span class="st">&#39;5.0&#39;</span>].count()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataframe with calculated average and count of ratings</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>final_rating <span class="op">=</span> pd.DataFrame({</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Average_Rating&#39;</span>: average_ratings,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Rating_Count&#39;</span>: count_ratings</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the dataframe by average of ratings in the descending order</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>final_rating <span class="op">=</span> final_rating.sort_values(by<span class="op">=</span><span class="st">&#39;Average_Rating&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co"># See the first five records of the &quot;final_rating&quot; dataset</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_rating.head())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>            Average_Rating  Rating_Count
0132793040                              
B00LGQ6HL8             5.0             5
B003DZJQQI             5.0            14
B005FDXF2C             5.0             7
B00I6CVPVC             5.0             7
B00B9KOCYA             5.0             8
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="20" id="zKU__5s1xhXi">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining a function to get the top n products based on the highest average rating and minimum interactions</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> top_n_products(dataframe, min_interactions<span class="op">=</span><span class="dv">5</span>, n<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">    - dataframe</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - min_interactions: Minimum number of ratings for the product to be considered.</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - n: Number of top products to return.</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - top_n: Dataframe of top n products.</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Finding products with minimum number of interactions</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    filtered_products <span class="op">=</span> dataframe[dataframe[<span class="st">&#39;Rating_Count&#39;</span>] <span class="op">&gt;=</span> min_interactions]</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sorting values with respect to average rating</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    sorted_products <span class="op">=</span> filtered_products.sort_values(by<span class="op">=</span><span class="st">&#39;Average_Rating&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the top n products</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>    top_n <span class="op">=</span> sorted_products.head(n)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> top_n</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<section
id="recommending-top-5-products-with-50-minimum-interactions-based-on-popularity"
class="cell markdown" id="F8l6373PxhXi">
<h3><strong>Recommending top 5 products with 50 minimum interactions
based on popularity</strong></h3>
</section>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="dBxdLiM_xhXi" data-outputId="bc18806d-8425-4b1a-f46b-d279546e5765">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>top_5_products <span class="op">=</span> top_n_products(final_rating, min_interactions<span class="op">=</span><span class="dv">50</span>, n<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_5_products)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>            Average_Rating  Rating_Count
0132793040                              
B001TH7GUU        4.871795            78
B003ES5ZUU        4.864130           184
B0019EHU8G        4.855556            90
B006W8U2MU        4.824561            57
B000QUUFRW        4.809524            84
</code></pre>
</div>
</div>
<section
id="recommending-top-5-products-with-100-minimum-interactions-based-on-popularity"
class="cell markdown" id="l9_xW_UMxhXj">
<h3><strong>Recommending top 5 products with 100 minimum interactions
based on popularity</strong></h3>
</section>
<div class="cell code" data-execution_count="22"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="dZgGZCUoxhXj" data-outputId="e529422d-62ea-4e13-ca7c-3f3d52d8eba4">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>top_5_products_100_interactions <span class="op">=</span> top_n_products(final_rating, min_interactions<span class="op">=</span><span class="dv">100</span>, n<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_5_products_100_interactions)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>            Average_Rating  Rating_Count
0132793040                              
B003ES5ZUU        4.864130           184
B000N99BBC        4.772455           167
B002WE6D44        4.770000           100
B007WTAJTO        4.701220           164
B002V88HFE        4.698113           106
</code></pre>
</div>
</div>
<div class="cell markdown" id="BL-m68a15JtT"
data-outputId="69132b0f-8d3f-4798-f6a0-249e17a3c822">
<p>We have recommended the <strong>top 5</strong> products by using the
popularity recommendation system. Now, let's build a recommendation
system using <strong>collaborative filtering.</strong></p>
</div>
<section id="model-2-collaborative-filtering-recommendation-system"
class="cell markdown" id="sJI5kiiGvOOK">
<h2><strong>Model 2: Collaborative Filtering Recommendation
System</strong></h2>
</section>
<section
id="building-a-baseline-user-user-similarity-based-recommendation-system"
class="cell markdown" id="skzc0N1_nVNB">
<h3><strong>Building a baseline user-user similarity based
recommendation system</strong></h3>
</section>
<div class="cell markdown" id="d4Uo_MYMnVNB">
<ul>
<li>Below, we are building <strong>similarity-based recommendation
systems</strong> using <code>cosine</code> similarity and using
<strong>KNN to find similar users</strong> which are the nearest
neighbor to the given user.<br />
</li>
<li>We will be using a new library, called <code>surprise</code>, to
build the remaining models. Let's first import the necessary classes and
functions from this library.</li>
</ul>
</div>
<div class="cell code" data-execution_count="23" id="UJ1wEylUpexj">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To compute the accuracy of models</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> accuracy</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.reader <span class="im">import</span> Reader</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Class for loading datasets</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.dataset <span class="im">import</span> Dataset</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For tuning model hyperparameters</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co"># For splitting the rating data in train and test datasets</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co"># For implementing similarity-based recommendation system</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.prediction_algorithms.knns <span class="im">import</span> KNNBasic</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="co"># For implementing matrix factorization based recommendation system</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.prediction_algorithms.matrix_factorization <span class="im">import</span> SVD</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="co"># for implementing K-Fold cross-validation</span></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.model_selection <span class="im">import</span> KFold</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="co"># For implementing clustering-based recommendation system</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> CoClustering</span></code></pre></div>
</div>
<div class="cell markdown" id="54MqVAtDTsnl">
<p><strong>Before building the recommendation systems, let's go over
some basic terminologies we are going to use:</strong></p>
</div>
<div class="cell markdown" id="Qsxb3xhnTsnl">
<p><strong>Relevant item:</strong> An item (product in this case) that
is actually <strong>rated higher than the threshold rating</strong> is
relevant, if the <strong>actual rating is below the threshold then it is
a non-relevant item</strong>.</p>
<p><strong>Recommended item:</strong> An item that's <strong>predicted
rating is higher than the threshold is a recommended item</strong>, if
the <strong>predicted rating is below the threshold then that product
will not be recommended to the user</strong>.</p>
</div>
<div class="cell markdown" id="moyLUHCuTsnl">
<p><strong>False Negative (FN):</strong> It is the <strong>frequency of
relevant items that are not recommended to the user</strong>. If the
relevant items are not recommended to the user, then the user might not
buy the product/item. This would result in the <strong>loss of
opportunity for the service provider</strong>, which they would like to
minimize.</p>
<p><strong>False Positive (FP):</strong> It is the <strong>frequency of
recommended items that are actually not relevant</strong>. In this case,
the recommendation system is not doing a good job of finding and
recommending the relevant items to the user. This would result in
<strong>loss of resources for the service provider</strong>, which they
would also like to minimize.</p>
</div>
<div class="cell markdown" id="Yuvc2VaZTsnl">
<p><strong>Recall:</strong> It is the <strong>fraction of actually
relevant items that are recommended to the user</strong>, i.e., if out
of 10 relevant products, 6 are recommended to the user then recall is
0.60. Higher the value of recall better is the model. It is one of the
metrics to do the performance assessment of classification models.</p>
<p><strong>Precision:</strong> It is the <strong>fraction of recommended
items that are relevant actually</strong>, i.e., if out of 10
recommended items, 6 are found relevant by the user then precision is
0.60. The higher the value of precision better is the model. It is one
of the metrics to do the performance assessment of classification
models.</p>
</div>
<div class="cell markdown" id="8NLc36Y8Tsnm">
<p><strong>While making a recommendation system, it becomes customary to
look at the performance of the model. In terms of how many
recommendations are relevant and vice-versa, below are some most used
performance metrics used in the assessment of recommendation
systems.</strong></p>
</div>
<section id="precisionk-recall-k-and-f1-scorek" class="cell markdown"
id="cqF8fRBqTsnm">
<h3><strong><a href="mailto:Precision@k" class="email">Precision@k</a>,
Recall@ k, and <a href="mailto:F1-score@k"
class="email">F1-score@k</a></strong></h3>
</section>
<div class="cell markdown" id="imMJNF0HTsnm">
<p><strong><a href="mailto:Precision@k"
class="email">Precision@k</a></strong> - It is the <strong>fraction of
recommended items that are relevant in <code>top k</code>
predictions</strong>. The value of k is the number of recommendations to
be provided to the user. One can choose a variable number of
recommendations to be given to a unique user.</p>
<p><strong><a href="mailto:Recall@k" class="email">Recall@k</a></strong>
- It is the <strong>fraction of relevant items that are recommended to
the user in <code>top k</code> predictions</strong>.</p>
<p><strong><a href="mailto:F1-score@k"
class="email">F1-score@k</a></strong> - It is the <strong>harmonic mean
of <a href="mailto:Precision@k" class="email">Precision@k</a> and <a
href="mailto:Recall@k" class="email">Recall@k</a></strong>. When
<strong><a href="mailto:precision@k" class="email">precision@k</a> and
<a href="mailto:recall@k" class="email">recall@k</a> both seem to be
important</strong> then it is useful to use this metric because it is
representative of both of them.</p>
</div>
<section id="some-useful-functions" class="cell markdown"
id="jBW4BUhWTsnm">
<h3><strong>Some useful functions</strong></h3>
</section>
<div class="cell markdown" id="QOBHKh0eTsnm">
<ul>
<li>Below function takes the <strong>recommendation model</strong> as
input and gives the <strong><a href="mailto:precision@k"
class="email">precision@k</a>, <a href="mailto:recall@k"
class="email">recall@k</a>, and <a href="mailto:F1-score@k"
class="email">F1-score@k</a></strong> for that model.<br />
</li>
<li>To compute <strong>precision and recall</strong>, <strong>top
k</strong> predictions are taken under consideration for each user.</li>
<li>We will use the precision and recall to compute the F1-score.</li>
</ul>
</div>
<div class="cell code" data-execution_count="24" id="Rxn-GahOTsnm">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> precision_recall_at_k(model, k <span class="op">=</span> <span class="dv">10</span>, threshold <span class="op">=</span> <span class="fl">3.5</span>):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Return precision and recall at k metrics for each user&quot;&quot;&quot;</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First map the predictions to each user</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    user_est_true <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Making predictions on the test data</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model.test(testset)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> uid, _, true_r, est, _ <span class="kw">in</span> predictions:</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>        user_est_true[uid].append((est, true_r))</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    precisions <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    recalls <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> uid, user_ratings <span class="kw">in</span> user_est_true.items():</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort user ratings by estimated value</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        user_ratings.sort(key <span class="op">=</span> <span class="kw">lambda</span> x: x[<span class="dv">0</span>], reverse <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of relevant items</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        n_rel <span class="op">=</span> <span class="bu">sum</span>((true_r <span class="op">&gt;=</span> threshold) <span class="cf">for</span> (_, true_r) <span class="kw">in</span> user_ratings)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of recommended items in top k</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        n_rec_k <span class="op">=</span> <span class="bu">sum</span>((est <span class="op">&gt;=</span> threshold) <span class="cf">for</span> (est, _) <span class="kw">in</span> user_ratings[:k])</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of relevant and recommended items in top k</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        n_rel_and_rec_k <span class="op">=</span> <span class="bu">sum</span>(((true_r <span class="op">&gt;=</span> threshold) <span class="kw">and</span> (est <span class="op">&gt;=</span> threshold))</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>                              <span class="cf">for</span> (est, true_r) <span class="kw">in</span> user_ratings[:k])</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Precision@K: Proportion of recommended items that are relevant</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>        precisions[uid] <span class="op">=</span> n_rel_and_rec_k <span class="op">/</span> n_rec_k <span class="cf">if</span> n_rec_k <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Recall@K: Proportion of relevant items that are recommended</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0</span></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>        recalls[uid] <span class="op">=</span> n_rel_and_rec_k <span class="op">/</span> n_rel <span class="cf">if</span> n_rel <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mean of all the predicted precisions are calculated.</span></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> <span class="bu">round</span>((<span class="bu">sum</span>(prec <span class="cf">for</span> prec <span class="kw">in</span> precisions.values()) <span class="op">/</span> <span class="bu">len</span>(precisions)), <span class="dv">3</span>)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mean of all the predicted recalls are calculated.</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> <span class="bu">round</span>((<span class="bu">sum</span>(rec <span class="cf">for</span> rec <span class="kw">in</span> recalls.values()) <span class="op">/</span> <span class="bu">len</span>(recalls)), <span class="dv">3</span>)</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>    accuracy.rmse(predictions)</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Precision: &#39;</span>, precision) <span class="co"># Command to print the overall precision</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Recall: &#39;</span>, recall) <span class="co"># Command to print the overall recall</span></span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;F_1 score: &#39;</span>, <span class="bu">round</span>((<span class="dv">2</span><span class="op">*</span>precision<span class="op">*</span>recall)<span class="op">/</span>(precision<span class="op">+</span>recall), <span class="dv">3</span>)) <span class="co"># Formula to compute the F-1 score</span></span></code></pre></div>
</div>
<div class="cell markdown" id="_ZmsamDVyek-">
<p><strong>Hints:</strong></p>
<ul>
<li>To compute <strong>precision and recall</strong>, a
<strong>threshold of 3.5 and k value of 10 can be considered for the
recommended and relevant ratings</strong>.</li>
<li>Think about the performance metric to choose.</li>
</ul>
</div>
<div class="cell markdown" id="8hxjJMTwnVNB">
<p>Below we are loading the <strong><code>rating</code>
dataset</strong>, which is a <strong>pandas DataFrame</strong>, into a
<strong>different format called
<code>surprise.dataset.DatasetAutoFolds</code></strong>, which is
required by this library. To do this, we will be <strong>using the
classes <code>Reader</code> and <code>Dataset</code>.</strong></p>
</div>
<div class="cell code" data-execution_count="25" id="rGfYDiOCpe4X">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiating Reader scale with expected rating scale</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>reader <span class="op">=</span> Reader(rating_scale<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">5</span>))</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Loading the rating dataset</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> Dataset.load_from_df(df_final[[<span class="st">&#39;AKM1MP6P0OYPR&#39;</span>, <span class="st">&#39;0132793040&#39;</span>, <span class="st">&#39;5.0&#39;</span>]], reader)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into train and test datasets</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>trainset, testset <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="DmHTEt7TnVNC">
<p>Now, we are <strong>ready to build the first baseline
similarity-based recommendation system</strong> using the cosine
similarity.</p>
</div>
<section
id="building-the-user-user-similarity-based-recommendation-system"
class="cell markdown" id="SVDfVHB4tQfU">
<h3><strong>Building the user-user Similarity-based Recommendation
System</strong></h3>
</section>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="vO3FL7iape8A" data-outputId="ae18c77f-c514-4b87-e6d7-35619ba0b0c8"
data-scrolled="false">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Declaring the similarity options</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>sim_options <span class="op">=</span> {</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;name&#39;</span>: <span class="st">&#39;cosine&#39;</span>,  <span class="co"># cosine similarity</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;user_based&#39;</span>: <span class="va">True</span>  <span class="co"># user-user similarity</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KNNBasic(sim_options<span class="op">=</span>sim_options, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model on the training data</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>model.fit(trainset)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>precision_recall_at_k(model)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE: 1.0119
Precision:  0.849
Recall:  0.861
F_1 score:  0.855
</code></pre>
</div>
</div>
<div class="cell markdown" id="nEuJK_A9Tsnn">
<p><strong>Write your observations here:</strong></p>
<p>RMSE of 1.0217 shows that the model's predictions are on average 1
rating away from the actual rating, in this context the margin of error
is relatively high.</p>
<p>Precision of 0.853 means that 85% of the time the model reccomends
something relevant to the user. Meaning it is quite effective in that
sense but there is room for improvement.</p>
<p>F_1 score of 0.859 shows a balanced performance between precision and
recall.</p>
</div>
<div class="cell markdown" id="reFD0-nsnVNC">
<p>Let's now <strong>predict rating for a user with
<code>userId=A3LDPF5FMB782Z</code> and
<code>productId=1400501466</code></strong> as shown below. Here the user
has already interacted or watched the product with productId
'1400501466' and given a rating of 5.</p>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Sxd23bZ9pe_x" data-outputId="a9848284-53bb-496b-f998-a19d8b50533b">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating for a sample user with an interacted product</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># User and product IDs</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>user_id <span class="op">=</span> <span class="st">&quot;A3LDPF5FMB782Z&quot;</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>product_id <span class="op">=</span> <span class="st">&quot;1400501466&quot;</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Making the prediction</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> model.predict(user_id, product_id, verbose<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting the estimated rating from the prediction object</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>estimated_rating <span class="op">=</span> prediction.est</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated Rating for User &#39;</span><span class="sc">{</span>user_id<span class="sc">}</span><span class="ss">&#39; and Product &#39;</span><span class="sc">{</span>product_id<span class="sc">}</span><span class="ss">&#39;: </span><span class="sc">{</span>estimated_rating<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>user: A3LDPF5FMB782Z item: 1400501466 r_ui = None   est = 4.29   {&#39;was_impossible&#39;: True, &#39;reason&#39;: &#39;Not enough neighbors.&#39;}
Estimated Rating for User &#39;A3LDPF5FMB782Z&#39; and Product &#39;1400501466&#39;: 4.294302343391025
</code></pre>
</div>
</div>
<div class="cell markdown" id="ENJcqG_wemRH">
<p><strong>Write your observations here:</strong></p>
<p>The system predicts a high rating of 4.30 for the user A3LDPF5FMB782Z
with the item 1400501466. The prediction was made despite facing
challenges due to data sparsity, as indicated by the was_impossible flag
being True and the reason 'Not enough neighbors.'. This lack of
sufficient similar users suggests a potential area of improvement for
the model.</p>
</div>
<div class="cell markdown" id="cj6ecbglTsno">
<p>Below is the <strong>list of users who have not seen the product with
product id "1400501466"</strong>.</p>
</div>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="xCRBMD-RTsno" data-outputId="456201cc-71ae-4dc8-ac67-8a9f3c853a46">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find unique user_id where prod_id is not equal to &quot;1400501466&quot;</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>unique_users <span class="op">=</span> df_final[df_final[<span class="st">&#39;0132793040&#39;</span>] <span class="op">!=</span> <span class="st">&quot;1400501466&quot;</span>][<span class="st">&#39;AKM1MP6P0OYPR&#39;</span>].unique()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(unique_users)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;A2ZR3YTMEEIIZ4&#39; &#39;A3CLWR1UUZT6TG&#39; &#39;A5JLAU2ARJ0BO&#39; ... &#39;A215WH6RUDUCMP&#39;
 &#39;A38C12950IM24P&#39; &#39;A2J4XMWKR8PPD0&#39;]
</code></pre>
</div>
</div>
<div class="cell markdown" id="KT42ecaSTsno">
<ul>
<li>It can be observed from the above list that <strong>user
"A34BZM6S9L7QI4" has not seen the product with productId
"1400501466"</strong> as this userId is a part of the above list.</li>
</ul>
</div>
<div class="cell markdown" id="EXSgq8OEnVNE">
<p><strong>Below we are predicting rating for
<code>userId=A34BZM6S9L7QI4</code> and
<code>prod_id=1400501466</code>.</strong></p>
</div>
<div class="cell code" data-execution_count="29"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PbFcBj1PpfEV" data-outputId="d9107d78-0ffd-4c73-e7aa-882e710719b9">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating for a sample user with a non interacted product</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>uid <span class="op">=</span> <span class="st">&#39;A3LDPF5FMB782Z&#39;</span>  <span class="co"># user ID</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>iid <span class="op">=</span> <span class="st">&#39;XYZ123&#39;</span>  <span class="co"># item ID (product ID)</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> model.predict(uid, iid, verbose<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>user: A3LDPF5FMB782Z item: XYZ123     r_ui = None   est = 4.29   {&#39;was_impossible&#39;: True, &#39;reason&#39;: &#39;User and/or item is unknown.&#39;}
</code></pre>
</div>
</div>
<div class="cell markdown" id="02rwld8yemRI">
<p><strong>Write your observations here:</strong></p>
<p>The recommendation system predicts a rating of 4.3 for user
A3LDPF5FMB782Z on the product XYZ123, which the user hasn't previously
interacted with. However, this prediction is less reliable because the
model flagged it as "impossible" due to the unfamiliarity with either
the user, the item, or both. This highlights the cold start problem,
where the system struggles to predict for new users or items. In such
cases, other recommendation strategies might be more suitable.</p>
</div>
<section
id="improving-similarity-based-recommendation-system-by-tuning-its-hyperparameters"
class="cell markdown" id="ejjof6csnVNF">
<h3><strong>Improving similarity-based recommendation system by tuning
its hyperparameters</strong></h3>
</section>
<div class="cell markdown" id="p2j4VvfQnVNF">
<p>Below, we will be tuning hyperparameters for the
<code>KNNBasic</code> algorithm. Let's try to understand some of the
hyperparameters of the KNNBasic algorithm:</p>
<ul>
<li><strong>k</strong> (int) – The (max) number of neighbors to take
into account for aggregation. Default is 40.</li>
<li><strong>min_k</strong> (int) – The minimum number of neighbors to
take into account for aggregation. If there are not enough neighbors,
the prediction is set to the global mean of all ratings. Default is
1.</li>
<li><strong>sim_options</strong> (dict) – A dictionary of options for
the similarity measure. And there are four similarity measures available
in surprise -
<ul>
<li>cosine</li>
<li>msd (default)</li>
<li>Pearson</li>
<li>Pearson baseline</li>
</ul></li>
</ul>
</div>
<div class="cell code" data-execution_count="32"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="9LmPbSUSTsnp" data-outputId="b87c5c62-3550-4324-fbf1-f3263624b06d">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting up parameter grid to tune the hyperparameters</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;k&#39;</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">60</span>, <span class="dv">80</span>, <span class="dv">100</span>],   <span class="co"># max neighbors</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_k&#39;</span>: [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>],   <span class="co"># min neighbors</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sim_options&#39;</span>: {</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;name&#39;</span>: [<span class="st">&#39;msd&#39;</span>, <span class="st">&#39;cosine&#39;</span>, <span class="st">&#39;pearson&#39;</span>, <span class="st">&#39;pearson_baseline&#39;</span>],</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;user_based&#39;</span>: [<span class="va">True</span>, <span class="va">False</span>]  <span class="co"># compute  similarities between users</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Performing 3-fold cross-validation to tune the hyperparameters</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>gs <span class="op">=</span> GridSearchCV(KNNBasic, param_grid, measures<span class="op">=</span>[<span class="st">&#39;rmse&#39;</span>], cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the data</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>reader <span class="op">=</span> Reader(line_format<span class="op">=</span><span class="st">&#39;user item rating&#39;</span>, rating_scale<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">5</span>))</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> Dataset.load_from_df(df_final[[<span class="st">&#39;AKM1MP6P0OYPR&#39;</span>, <span class="st">&#39;0132793040&#39;</span>, <span class="st">&#39;5.0&#39;</span>]], reader)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> data.build_full_trainset()</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>gs.fit(data)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Best RMSE score</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best RMSE score:&quot;</span>, gs.best_score[<span class="st">&#39;rmse&#39;</span>])</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Combination of parameters that gave the best RMSE score</span></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameters combination:&quot;</span>, gs.best_params[<span class="st">&#39;rmse&#39;</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Computing the pearson similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Estimating biases using als...
Computing the pearson_baseline similarity matrix...
Done computing similarity matrix.
Best RMSE score: 0.9703440889887901
Best parameters combination: {&#39;k&#39;: 100, &#39;min_k&#39;: 5, &#39;sim_options&#39;: {&#39;name&#39;: &#39;cosine&#39;, &#39;user_based&#39;: True}}
</code></pre>
</div>
</div>
<div class="cell markdown" id="L2fHNvu7nVNF">
<p>Once the grid search is <strong>complete</strong>, we can get the
<strong>optimal values for each of those hyperparameters</strong>.</p>
</div>
<div class="cell markdown" id="NHWgxu_YnVNG">
<p>Now, let's build the <strong>final model by using tuned values of the
hyperparameters</strong>, which we received by using <strong>grid search
cross-validation</strong>.</p>
</div>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PujRJA8X_JEJ" data-outputId="391fbcd3-4d03-493e-fdf0-f10c1135c730">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using the optimal similarity measure for user-user based collaborative filtering</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> gs.best_params[<span class="st">&#39;rmse&#39;</span>]</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> best_params[<span class="st">&#39;k&#39;</span>]</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>sim_options <span class="op">=</span> best_params[<span class="st">&#39;sim_options&#39;</span>]</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating an instance of KNNBasic with optimal hyperparameter values</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>algo <span class="op">=</span> KNNBasic(k<span class="op">=</span>k, sim_options<span class="op">=</span>sim_options)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Training the algorithm on the trainset</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> data.build_full_trainset()</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>algo.fit(trainset)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Let us compute precision@k and recall@k also with k =10</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>precision_recall_at_k(algo, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the cosine similarity matrix...
Done computing similarity matrix.
RMSE: 0.8492
Precision:  0.864
Recall:  0.888
F_1 score:  0.876
</code></pre>
</div>
</div>
<div class="cell markdown" id="yHsWvFjKTsnp">
<p><strong>Write your observations here:</strong></p>
<p>RMSE of 0.8492 means that the model's predicted rating for certain
products deviate by 0.85 points to the actual user given ratings. This
model's RMSE is better than the others but still it is relatively quite
high given that the ratings are given on a scale from 1-5</p>
<p>Precision of 0.864 means that if amazon were to suggest the top 10
products to a user, then 86.4% of them the user would indeed like or
purchase. Which in this instance is really good.</p>
<p>Recall of 0.888 means that out of all the products the user might
like, amazon would successfully reccommend 88.8% of them in the top 10
products.</p>
<p>F_1 score of 0.86 is quite high meaning that the model is both
precise and sensitive.</p>
</div>
<section id="steps" class="cell markdown" id="YhcAXK0CnVNG">
<h3><strong>Steps:</strong></h3>
<ul>
<li><strong>Predict rating for the user with
<code>userId="A3LDPF5FMB782Z"</code>, and
<code>prod_id= "1400501466"</code> using the optimized
model</strong></li>
<li><strong>Predict rating for <code>userId="A34BZM6S9L7QI4"</code> who
has not interacted with <code>prod_id ="1400501466"</code>, by using the
optimized model</strong></li>
<li><strong>Compare the output with the output from the baseline
model</strong></li>
</ul>
</section>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="WXkVw5ws8nyT" data-outputId="7dd5abe3-3693-40d9-e8a4-6bd9e8d304ec">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> KNNBasic, Dataset, Reader</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the optimal parameters</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>sim_options <span class="op">=</span> {</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;name&#39;</span>: <span class="st">&#39;cosine&#39;</span>,  <span class="co"># use cosine similarity measure (as an example)</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;user_based&#39;</span>: <span class="va">True</span>  <span class="co"># user-based collaborative filtering</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a KNNBasic instance with the optimal parameters</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>optimized_algo <span class="op">=</span> KNNBasic(sim_options<span class="op">=</span>sim_options)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the algorithm on your dataset</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> data.build_full_trainset()</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>optimized_algo.fit(trainset)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the cosine similarity matrix...
Done computing similarity matrix.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="36">
<pre><code>&lt;surprise.prediction_algorithms.knns.KNNBasic at 0x7f5df6ed7910&gt;</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="38"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="FgV63lHiq1TV" data-outputId="8c6a18c7-7792-4a94-9183-35f1d974204e">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use sim_user_user_optimized model to recommend for userId &quot;A3LDPF5FMB782Z&quot; and productId 1400501466</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>pred_optimized_A3LDPF5FMB782Z <span class="op">=</span> optimized_algo.predict(<span class="st">&quot;A3LDPF5FMB782Z&quot;</span>, <span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Predicted rating for user A3LDPF5FMB782Z for product 1400501466 using the optimized model: </span><span class="sc">{</span>pred_optimized_A3LDPF5FMB782Z<span class="sc">.</span>est<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Predicted rating for user A3LDPF5FMB782Z for product 1400501466 using the optimized model: 3.3333333333333335
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="HXO2Ztjhq1bN" data-outputId="54b69f6c-2698-46cf-c6d3-aca321c421a9">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use sim_user_user_optimized model to recommend for userId &quot;A34BZM6S9L7QI4&quot; and productId &quot;1400501466&quot;</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>pred_optimized_A34BZM6S9L7QI4 <span class="op">=</span> optimized_algo.predict(<span class="st">&quot;A34BZM6S9L7QI4&quot;</span>, <span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Predicted rating for user A34BZM6S9L7QI4 for product 1400501466 using the optimized model: </span><span class="sc">{</span>pred_optimized_A34BZM6S9L7QI4<span class="sc">.</span>est<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Predicted rating for user A34BZM6S9L7QI4 for product 1400501466 using the optimized model: 1.9931452874171676
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="58"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="2Ziof7tQ9Koi" data-outputId="fb533ea4-c39d-44ce-a9b7-ef383d74bcd0">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> BaselineOnly</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the BaselineOnly algorithm</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>bsl_options <span class="op">=</span> {<span class="st">&#39;method&#39;</span>: <span class="st">&#39;sgd&#39;</span>, <span class="st">&#39;n_epochs&#39;</span>: <span class="dv">20</span>}  <span class="co"># using Stochastic Gradient Descent</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>algo1 <span class="op">=</span> BaselineOnly(bsl_options<span class="op">=</span>bsl_options)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>algo1.fit(trainset)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert raw ids to inner ids</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>inner_uid <span class="op">=</span> trainset.to_inner_uid(<span class="st">&quot;A3LDPF5FMB782Z&quot;</span>)</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>inner_iid <span class="op">=</span> trainset.to_inner_iid(<span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute baseline estimate for the user and the item</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>baseline_estimate_A3LDPF5FMB782Z <span class="op">=</span> trainset.global_mean <span class="op">+</span> algo1.bu[inner_uid] <span class="op">+</span> algo1.bi[inner_iid]</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Baseline estimate for user A3LDPF5FMB782Z for product 1400501466: </span><span class="sc">{</span>baseline_estimate_A3LDPF5FMB782Z<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Do the same for the other user</span></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>inner_uid <span class="op">=</span> trainset.to_inner_uid(<span class="st">&quot;A34BZM6S9L7QI4&quot;</span>)</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>baseline_estimate_A34BZM6S9L7QI4 <span class="op">=</span> trainset.global_mean <span class="op">+</span> algo1.bu[inner_uid] <span class="op">+</span> algo1.bi[inner_iid]</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Baseline estimate for user A34BZM6S9L7QI4 for product 1400501466: </span><span class="sc">{</span>baseline_estimate_A34BZM6S9L7QI4<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Estimating biases using sgd...
Baseline estimate for user A3LDPF5FMB782Z for product 1400501466: 3.8852456053763422
Baseline estimate for user A34BZM6S9L7QI4 for product 1400501466: 4.191848101756269
</code></pre>
</div>
</div>
<div class="cell markdown" id="s5i-OPprNF2e">
<p><strong>Write your observations here:</strong></p>
<p>This shows us that the optimized model with the first user was much
more accurate as it was only off by 0.5 points. Where as for the second
user it was over 2 points therefore inneffective.</p>
</div>
<section
id="identifying-similar-users-to-a-given-user-nearest-neighbors"
class="cell markdown" id="op_zwO_FnVNH">
<h3><strong>Identifying similar users to a given user (nearest
neighbors)</strong></h3>
</section>
<div class="cell markdown" id="o2QsfqhanVNH">
<p>We can also find out <strong>similar users to a given user</strong>
or its <strong>nearest neighbors</strong> based on this KNNBasic
algorithm. Below, we are finding the 5 most similar users to the first
user in the list with internal id 0, based on the <code>msd</code>
distance metric.</p>
</div>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="TbFle7cKmBJG" data-outputId="cba842ed-aea6-4e7c-c536-0aebd2ca020c">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0 is the inner id of the above user</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>sim_options <span class="op">=</span> {</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;name&#39;</span>: <span class="st">&#39;msd&#39;</span>,  <span class="co"># specify the distance metric to be msd</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;user_based&#39;</span>: <span class="va">True</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>algo <span class="op">=</span> KNNBasic(sim_options<span class="op">=</span>sim_options)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>algo.fit(trainset)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the 5 most similar users to the user with internal id 0</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>inner_uid <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>neighbors <span class="op">=</span> algo.get_neighbors(inner_uid, k<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert internal ids of the neighbors back to raw ids</span></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>raw_uids <span class="op">=</span> [trainset.to_raw_uid(inner_id) <span class="cf">for</span> inner_id <span class="kw">in</span> neighbors]</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>inner_uid <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>neighbors <span class="op">=</span> algo.get_neighbors(inner_uid, k<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert internal ids of the neighbors back to raw ids</span></span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>raw_uids <span class="op">=</span> [trainset.to_raw_uid(inner_id) <span class="cf">for</span> inner_id <span class="kw">in</span> neighbors]</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;5 most similar users to user with internal id 0 are: </span><span class="sc">{</span>raw_uids<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the msd similarity matrix...
Done computing similarity matrix.
5 most similar users to user with internal id 0 are: [&#39;AW3LX47IHPFRL&#39;, &#39;A19N3S7CBSU6O7&#39;, &#39;A1VHCO8RQFIGQJ&#39;, &#39;A1OGCPMSIVK7G4&#39;, &#39;ABVYGB2TKBO8F&#39;]
</code></pre>
</div>
</div>
<section
id="implementing-the-recommendation-algorithm-based-on-optimized-knnbasic-model"
class="cell markdown" id="Z0NsrX_anVNH">
<h3><strong>Implementing the recommendation algorithm based on optimized
KNNBasic model</strong></h3>
</section>
<div class="cell markdown" id="U3ESobDynVNI">
<p>Below we will be implementing a function where the input parameters
are:</p>
<ul>
<li>data: A <strong>rating</strong> dataset</li>
<li>user_id: A user id <strong>against which we want the
recommendations</strong></li>
<li>top_n: The <strong>number of products we want to
recommend</strong></li>
<li>algo: the algorithm we want to use <strong>for predicting the
ratings</strong></li>
<li>The output of the function is a <strong>set of top_n items</strong>
recommended for the given user_id based on the given algorithm</li>
</ul>
</div>
<div class="cell code" data-execution_count="45" id="vW9V1Tk65HlY">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_recommendations(data, user_id, top_n, algo):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creating an empty list to store the recommended product ids</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    recommendations <span class="op">=</span> []</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creating an user item interactions matrix</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    user_item_interactions_matrix <span class="op">=</span> data.pivot(index <span class="op">=</span> <span class="st">&#39;user_id&#39;</span>, columns <span class="op">=</span> <span class="st">&#39;prod_id&#39;</span>, values <span class="op">=</span> <span class="st">&#39;rating&#39;</span>)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extracting those product ids which the user_id has not interacted yet</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    non_interacted_products <span class="op">=</span> user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Looping through each of the product ids which user_id has not interacted yet</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item_id <span class="kw">in</span> non_interacted_products:</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predicting the ratings for those non interacted product ids by this user</span></span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>        est <span class="op">=</span> algo.predict(user_id, item_id).est</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Appending the predicted ratings</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>        recommendations.append((item_id, est))</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sorting the predicted ratings in descending order</span></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>    recommendations.sort(key <span class="op">=</span> <span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> recommendations[:top_n] <span class="co"># Returing top n highest predicted rating products for this user</span></span></code></pre></div>
</div>
<div class="cell markdown" id="Oj_S7kh4nVNI">
<p><strong>Predicting top 5 products for userId = "A3LDPF5FMB782Z" with
similarity based recommendation system</strong></p>
</div>
<div class="cell code" data-execution_count="49"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="qWbR85mI5Hrk" data-outputId="866f5fd4-1cb1-4a8a-ae6e-8e9f5995bc4c">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>df_final.columns <span class="op">=</span> [<span class="st">&#39;user_id&#39;</span>, <span class="st">&#39;prod_id&#39;</span>, <span class="st">&#39;rating&#39;</span>, <span class="st">&#39;timestamp&#39;</span>]</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Making top 5 recommendations for user_id &quot;A3LDPF5FMB782Z&quot; with a similarity-based recommendation engine</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>recommended_products <span class="op">=</span> get_recommendations(data<span class="op">=</span>df_final, user_id<span class="op">=</span><span class="st">&#39;A3LDPF5FMB782Z&#39;</span>, top_n<span class="op">=</span><span class="dv">5</span>, algo<span class="op">=</span>optimized_algo)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Outputting the recommendations</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Top 5 recommended products for user A3LDPF5FMB782Z are: </span><span class="sc">{</span>recommended_products<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Top 5 recommended products for user A3LDPF5FMB782Z are: [(&#39;1400599997&#39;, 5), (&#39;B00000DM9W&#39;, 5), (&#39;B00000K4KH&#39;, 5), (&#39;B00001P4XH&#39;, 5), (&#39;B00001W0DI&#39;, 5)]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="50"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="b5WfIX0Z6_q2" data-outputId="4f7342fc-8650-4a3b-c0d9-31de43cd3020">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Building the dataframe for above recommendations with columns &quot;prod_id&quot; and &quot;predicted_ratings&quot;</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>recommendations <span class="op">=</span> get_recommendations(df_final, <span class="st">&quot;A3LDPF5FMB782Z&quot;</span>, <span class="dv">5</span>, optimized_algo)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>df_recommendations <span class="op">=</span> pd.DataFrame(recommendations, columns<span class="op">=</span>[<span class="st">&quot;prod_id&quot;</span>, <span class="st">&quot;predicted_ratings&quot;</span>])</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_recommendations)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>      prod_id  predicted_ratings
0  1400599997                  5
1  B00000DM9W                  5
2  B00000K4KH                  5
3  B00001P4XH                  5
4  B00001W0DI                  5
</code></pre>
</div>
</div>
<section
id="item-item-similarity-based-collaborative-filtering-recommendation-system"
class="cell markdown" id="QgbzJKk7Tsnr">
<h3><strong>Item-Item Similarity-based Collaborative Filtering
Recommendation System</strong></h3>
</section>
<div class="cell markdown" id="qTJu_2hcTsnr">
<ul>
<li>Above we have seen <strong>similarity-based collaborative
filtering</strong> where similarity is calculated <strong>between
users</strong>. Now let us look into similarity-based collaborative
filtering where similarity is seen <strong>between items</strong>.</li>
</ul>
</div>
<div class="cell code" data-execution_count="51"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="W5RMcdzjTsns" data-outputId="9741bd0a-dd9c-4c06-ec9c-886b597d6b3b"
data-scrolled="false">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise <span class="im">import</span> KNNBasic, accuracy</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> surprise.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define the similarity options for item-item collaborative filtering</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>sim_options <span class="op">=</span> {</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;name&#39;</span>: <span class="st">&#39;cosine&#39;</span>,</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;user_based&#39;</span>: <span class="va">False</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Use KNNBasic algorithm with the defined similarity options</span></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>algo <span class="op">=</span> KNNBasic(sim_options<span class="op">=</span>sim_options)</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>trainset, testset <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the algorithm on the trainset</span></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>algo.fit(trainset)</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Predict ratings for the test set</span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> algo.test(testset)</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RMSE</span></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> accuracy.rmse(predictions)</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Compute precision@k, recall@k, and f_1 score with k = 10</span></span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> precision_recall_at_k(predictions, k<span class="op">=</span><span class="dv">10</span>, threshold<span class="op">=</span><span class="fl">3.5</span>):</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Return precision and recall at k metrics for each user&quot;&quot;&quot;</span></span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First map the predictions to each user.</span></span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a>    user_est_true <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> uid, _, true_r, est, _ <span class="kw">in</span> predictions:</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a>        user_est_true[uid].append((est, true_r))</span>
<span id="cb63-34"><a href="#cb63-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-35"><a href="#cb63-35" aria-hidden="true" tabindex="-1"></a>    precisions <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb63-36"><a href="#cb63-36" aria-hidden="true" tabindex="-1"></a>    recalls <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb63-37"><a href="#cb63-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> uid, user_ratings <span class="kw">in</span> user_est_true.items():</span>
<span id="cb63-38"><a href="#cb63-38" aria-hidden="true" tabindex="-1"></a>        user_ratings.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">0</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb63-39"><a href="#cb63-39" aria-hidden="true" tabindex="-1"></a>        n_rel <span class="op">=</span> <span class="bu">sum</span>((true_r <span class="op">&gt;=</span> threshold) <span class="cf">for</span> (_, true_r) <span class="kw">in</span> user_ratings)</span>
<span id="cb63-40"><a href="#cb63-40" aria-hidden="true" tabindex="-1"></a>        n_rec_k <span class="op">=</span> <span class="bu">sum</span>((est <span class="op">&gt;=</span> threshold) <span class="cf">for</span> (est, _) <span class="kw">in</span> user_ratings[:k])</span>
<span id="cb63-41"><a href="#cb63-41" aria-hidden="true" tabindex="-1"></a>        n_rel_and_rec_k <span class="op">=</span> <span class="bu">sum</span>(((true_r <span class="op">&gt;=</span> threshold) <span class="kw">and</span> (est <span class="op">&gt;=</span> threshold))</span>
<span id="cb63-42"><a href="#cb63-42" aria-hidden="true" tabindex="-1"></a>                              <span class="cf">for</span> (est, true_r) <span class="kw">in</span> user_ratings[:k])</span>
<span id="cb63-43"><a href="#cb63-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-44"><a href="#cb63-44" aria-hidden="true" tabindex="-1"></a>        precisions[uid] <span class="op">=</span> n_rel_and_rec_k <span class="op">/</span> n_rec_k <span class="cf">if</span> n_rec_k <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb63-45"><a href="#cb63-45" aria-hidden="true" tabindex="-1"></a>        recalls[uid] <span class="op">=</span> n_rel_and_rec_k <span class="op">/</span> n_rel <span class="cf">if</span> n_rel <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb63-46"><a href="#cb63-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-47"><a href="#cb63-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> precisions, recalls</span>
<span id="cb63-48"><a href="#cb63-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-49"><a href="#cb63-49" aria-hidden="true" tabindex="-1"></a>precisions, recalls <span class="op">=</span> precision_recall_at_k(predictions, k<span class="op">=</span><span class="dv">10</span>, threshold<span class="op">=</span><span class="fl">3.5</span>)</span>
<span id="cb63-50"><a href="#cb63-50" aria-hidden="true" tabindex="-1"></a>precision_at_k <span class="op">=</span> <span class="bu">sum</span>(prec <span class="cf">for</span> prec <span class="kw">in</span> precisions.values()) <span class="op">/</span> <span class="bu">len</span>(precisions)</span>
<span id="cb63-51"><a href="#cb63-51" aria-hidden="true" tabindex="-1"></a>recall_at_k <span class="op">=</span> <span class="bu">sum</span>(rec <span class="cf">for</span> rec <span class="kw">in</span> recalls.values()) <span class="op">/</span> <span class="bu">len</span>(recalls)</span>
<span id="cb63-52"><a href="#cb63-52" aria-hidden="true" tabindex="-1"></a>f1_score_at_k <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (precision_at_k <span class="op">*</span> recall_at_k) <span class="op">/</span> (precision_at_k <span class="op">+</span> recall_at_k)</span>
<span id="cb63-53"><a href="#cb63-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-54"><a href="#cb63-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Precision@10: </span><span class="sc">{</span>precision_at_k<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb63-55"><a href="#cb63-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Recall@10: </span><span class="sc">{</span>recall_at_k<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb63-56"><a href="#cb63-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;F1 Score@10: </span><span class="sc">{</span>f1_score_at_k<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the cosine similarity matrix...
Done computing similarity matrix.
RMSE: 1.0287
Precision@10: 0.8284
Recall@10: 0.8137
F1 Score@10: 0.8210
</code></pre>
</div>
</div>
<div class="cell markdown" id="ni9LoeUVTsns">
<p><strong>Write your observations here:</strong></p>
<p>RMSE of 1.0287 is really high which indicates big difference between
ratings</p>
<p>Precision of 82.84% means that around 82.84% of the top 10
recommended items are relevant which is high and good.</p>
<p>Recall of 81.37% shows the top 10 recommended items capture 81% of
the relevant products to the user.</p>
<p>The F_1 score of 0.821 tells us that the model maintains a good
balance between precision and recall.</p>
</div>
<div class="cell markdown" id="jFbcDQmxTsns">
<p>Let's now <strong>predict a rating for a user with
<code>userId = A3LDPF5FMB782Z</code> and
<code>prod_Id = 1400501466</code></strong> as shown below. Here the user
has already interacted or watched the product with productId
"1400501466".</p>
</div>
<div class="cell code" data-execution_count="59"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="JsF-aaWYTsns" data-outputId="c65c05d1-4bbf-4a9c-fad3-71a7c690dff8">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating for a sample user with an interacted product</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>predicted_rating <span class="op">=</span> algo.predict(<span class="st">&quot;A3LDPF5FMB782Z&quot;</span>, <span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Predicted rating for user A3LDPF5FMB782Z for product 1400501466: </span><span class="sc">{</span>predicted_rating<span class="sc">.</span>est<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>inner_uid <span class="op">=</span> trainset.to_inner_uid(<span class="st">&quot;A3LDPF5FMB782Z&quot;</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>inner_iid <span class="op">=</span> trainset.to_inner_iid(<span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>user_bias <span class="op">=</span> algo1.bu[inner_uid]</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>item_bias <span class="op">=</span> algo1.bi[inner_iid]</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>baseline_estimate <span class="op">=</span> trainset.global_mean <span class="op">+</span> user_bias <span class="op">+</span> item_bias</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Baseline estimate for user A3LDPF5FMB782Z for product 1400501466: </span><span class="sc">{</span>baseline_estimate<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Predicted rating for user A3LDPF5FMB782Z for product 1400501466: 4.2631578947368425
Baseline estimate for user A3LDPF5FMB782Z for product 1400501466: 3.8852456053763422
</code></pre>
</div>
</div>
<div class="cell markdown" id="BqKGZoAtTsns">
<p>Below we are <strong>predicting rating for the
<code>userId = A34BZM6S9L7QI4</code> and
<code>prod_id = 1400501466</code></strong>.</p>
</div>
<div class="cell code" data-execution_count="60"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5yILOxXRTsns" data-outputId="5d09c963-6eb3-476f-b45b-e547b78f487e">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating for a sample user with a non interacted product</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating for a sample user with an interacted product</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>predicted_rating <span class="op">=</span> algo.predict(<span class="st">&quot;A34BZM6S9L7QI4&quot;</span>, <span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Predicted rating for user A34BZM6S9L7QI4 for product 1400501466: </span><span class="sc">{</span>predicted_rating<span class="sc">.</span>est<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>inner_uid <span class="op">=</span> trainset.to_inner_uid(<span class="st">&quot;A34BZM6S9L7QI4&quot;</span>)</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>inner_iid <span class="op">=</span> trainset.to_inner_iid(<span class="st">&quot;1400501466&quot;</span>)</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>user_bias <span class="op">=</span> algo1.bu[inner_uid]</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>item_bias <span class="op">=</span> algo1.bi[inner_iid]</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>baseline_estimate <span class="op">=</span> trainset.global_mean <span class="op">+</span> user_bias <span class="op">+</span> item_bias</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Baseline estimate for user A34BZM6S9L7QI4 for product 1400501466: </span><span class="sc">{</span>baseline_estimate<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Predicted rating for user A34BZM6S9L7QI4 for product 1400501466: 4.0
Baseline estimate for user A34BZM6S9L7QI4 for product 1400501466: 4.191848101756269
</code></pre>
</div>
</div>
<section id="hyperparameter-tuning-the-item-item-similarity-based-model"
class="cell markdown" id="meSvpNLj_EjD">
<h3><strong>Hyperparameter tuning the item-item similarity-based
model</strong></h3>
<ul>
<li>Use the following values for the param_grid and tune the model.
<ul>
<li>'k': [10, 20, 30]</li>
<li>'min_k': [3, 6, 9]</li>
<li>'sim_options': {'name': ['msd', 'cosine']</li>
<li>'user_based': [False]</li>
</ul></li>
<li>Use GridSearchCV() to tune the model using the 'rmse' measure</li>
<li>Print the best score and best parameters</li>
</ul>
</section>
<div class="cell code" data-execution_count="61"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="f5bcZ3HgTsnt" data-outputId="e7f09fce-2309-4bcf-ed16-ef582143040b">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting up parameter grid to tune the hyperparameters</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;k&#39;</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_k&#39;</span>: [<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">9</span>],</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;sim_options&#39;</span>: {</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;name&#39;</span>: [<span class="st">&#39;msd&#39;</span>, <span class="st">&#39;cosine&#39;</span>],</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;user_based&#39;</span>: [<span class="va">False</span>]</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Performing 3-fold cross validation to tune the hyperparameters</span></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(KNNBasic, param_grid, measures<span class="op">=</span>[<span class="st">&#39;rmse&#39;</span>], cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the data</span></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>grid_search.fit(data)</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the best RMSE score</span></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best RMSE score:&quot;</span>, grid_search.best_score[<span class="st">&#39;rmse&#39;</span>])</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the combination of parameters that gave the best RMSE score</span></span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameters:&quot;</span>, grid_search.best_params[<span class="st">&#39;rmse&#39;</span>])</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the msd similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Computing the cosine similarity matrix...
Done computing similarity matrix.
Best RMSE score: 0.974834343421553
Best parameters: {&#39;k&#39;: 20, &#39;min_k&#39;: 6, &#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;user_based&#39;: False}}
</code></pre>
</div>
</div>
<div class="cell markdown" id="1psOlx6zTsnt">
<p>Once the <strong>grid search</strong> is complete, we can get the
<strong>optimal values for each of those hyperparameters as shown
above.</strong></p>
</div>
<div class="cell markdown" id="JrSTaQemTsnt">
<p>Now let's build the <strong>final model</strong> by using
<strong>tuned values of the hyperparameters</strong> which we received
by using grid search cross-validation.</p>
</div>
<section
id="use-the-best-parameters-from-gridsearchcv-to-build-the-optimized-item-item-similarity-based-model-compare-the-performance-of-the-optimized-model-with-the-baseline-model"
class="cell markdown" id="kOS9Dwnd_LN6">
<h3><strong>Use the best parameters from GridSearchCV to build the
optimized item-item similarity-based model. Compare the performance of
the optimized model with the baseline model.</strong></h3>
</section>
<div class="cell code" data-execution_count="65"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="mBKjNMPfIvsT" data-outputId="d151f252-18cb-4ee2-c9e6-52273f70b9d1">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> precision_recall_at_k(predictions, k<span class="op">=</span><span class="dv">10</span>, threshold<span class="op">=</span><span class="fl">3.5</span>):</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;Return precision and recall at k metrics for each user.&#39;&#39;&#39;</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First map the predictions to each user.</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    user_est_true <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> uid, _, true_r, est, _ <span class="kw">in</span> predictions:</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>        current <span class="op">=</span> user_est_true.get(uid, [])</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>        current.append((est, true_r))</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>        user_est_true[uid] <span class="op">=</span> current</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>    precisions <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>    recalls <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> uid, user_ratings <span class="kw">in</span> user_est_true.items():</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort user ratings by estimated value</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>        user_ratings.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">0</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of relevant items</span></span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>        n_rel <span class="op">=</span> <span class="bu">sum</span>((true_r <span class="op">&gt;=</span> threshold) <span class="cf">for</span> (_, true_r) <span class="kw">in</span> user_ratings)</span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of recommended items in top k</span></span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>        n_rec_k <span class="op">=</span> <span class="bu">sum</span>((est <span class="op">&gt;=</span> threshold) <span class="cf">for</span> (est, _) <span class="kw">in</span> user_ratings[:k])</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number of relevant and recommended items in top k</span></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>        n_rel_and_rec_k <span class="op">=</span> <span class="bu">sum</span>(((true_r <span class="op">&gt;=</span> threshold) <span class="kw">and</span> (est <span class="op">&gt;=</span> threshold))</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>                              <span class="cf">for</span> (est, true_r) <span class="kw">in</span> user_ratings[:k])</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Precision@K: Proportion of recommended items that are relevant</span></span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>        precisions[uid] <span class="op">=</span> n_rel_and_rec_k <span class="op">/</span> n_rec_k <span class="cf">if</span> n_rec_k <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Recall@K: Proportion of relevant items that are recommended</span></span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a>        recalls[uid] <span class="op">=</span> n_rel_and_rec_k <span class="op">/</span> n_rel <span class="cf">if</span> n_rel <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> precisions, recalls</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-35"><a href="#cb71-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the above function</span></span>
<span id="cb71-36"><a href="#cb71-36" aria-hidden="true" tabindex="-1"></a>precisions, recalls <span class="op">=</span> precision_recall_at_k(predictions_optimized, k<span class="op">=</span><span class="dv">10</span>, threshold<span class="op">=</span><span class="fl">3.5</span>)</span>
<span id="cb71-37"><a href="#cb71-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-38"><a href="#cb71-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating average precision and recall</span></span>
<span id="cb71-39"><a href="#cb71-39" aria-hidden="true" tabindex="-1"></a>avg_precision <span class="op">=</span> <span class="bu">sum</span>(prec <span class="cf">for</span> prec <span class="kw">in</span> precisions.values()) <span class="op">/</span> <span class="bu">len</span>(precisions)</span>
<span id="cb71-40"><a href="#cb71-40" aria-hidden="true" tabindex="-1"></a>avg_recall <span class="op">=</span> <span class="bu">sum</span>(rec <span class="cf">for</span> rec <span class="kw">in</span> recalls.values()) <span class="op">/</span> <span class="bu">len</span>(recalls)</span>
<span id="cb71-41"><a href="#cb71-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-42"><a href="#cb71-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating f1_score</span></span>
<span id="cb71-43"><a href="#cb71-43" aria-hidden="true" tabindex="-1"></a>avg_f1_score <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (avg_precision <span class="op">*</span> avg_recall) <span class="op">/</span> (avg_precision <span class="op">+</span> avg_recall)</span>
<span id="cb71-44"><a href="#cb71-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-45"><a href="#cb71-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision@10: </span><span class="sc">{</span>avg_precision<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb71-46"><a href="#cb71-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall@10: </span><span class="sc">{</span>avg_recall<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb71-47"><a href="#cb71-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score@10: </span><span class="sc">{</span>avg_f1_score<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Precision@10: 0.8297340849920208
Recall@10: 0.9039846107910203
F1 Score@10: 0.8652693723681448
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="67"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="dSeiM1qeTsnt" data-outputId="7396bc6a-ac5a-466b-d1b6-9473dd70c905">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training the algorithm on the trainset</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>trainset, testset <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating an instance of KNNBasic with optimal hyperparameter values</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>optimized_algo <span class="op">=</span> KNNBasic(k<span class="op">=</span><span class="dv">20</span>, min_k<span class="op">=</span><span class="dv">6</span>, sim_options<span class="op">=</span>{<span class="st">&#39;name&#39;</span>: <span class="st">&#39;msd&#39;</span>, <span class="st">&#39;user_based&#39;</span>: <span class="va">False</span>})</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>optimized_algo.fit(trainset)</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting ratings for the testset</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>predictions_optimized <span class="op">=</span> optimized_algo.test(testset)</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating RMSE</span></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>rmse_optimized <span class="op">=</span> accuracy.rmse(predictions_optimized)</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a><span class="co"># For precision@k and recall@k, use the precision_recall_at_k function</span></span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>precisions, recalls <span class="op">=</span> precision_recall_at_k(predictions_optimized, k<span class="op">=</span><span class="dv">10</span>, threshold<span class="op">=</span><span class="fl">3.5</span>)</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating average precision and recall</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>avg_precision <span class="op">=</span> <span class="bu">sum</span>(prec <span class="cf">for</span> prec <span class="kw">in</span> precisions.values()) <span class="op">/</span> <span class="bu">len</span>(precisions)</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>avg_recall <span class="op">=</span> <span class="bu">sum</span>(rec <span class="cf">for</span> rec <span class="kw">in</span> recalls.values()) <span class="op">/</span> <span class="bu">len</span>(recalls)</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating f1_score</span></span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>avg_f1_score <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (avg_precision <span class="op">*</span> avg_recall) <span class="op">/</span> (avg_precision <span class="op">+</span> avg_recall)</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Optimized RMSE: </span><span class="sc">{</span>rmse_optimized<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Precision@10: </span><span class="sc">{</span>avg_precision<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Recall@10: </span><span class="sc">{</span>avg_recall<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;F1 Score@10: </span><span class="sc">{</span>avg_f1_score<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computing the msd similarity matrix...
Done computing similarity matrix.
RMSE: 0.9752
Optimized RMSE: 0.9751572811411542
Precision@10: 0.8297340849920208
Recall@10: 0.9039846107910203
F1 Score@10: 0.8652693723681448
</code></pre>
</div>
</div>
</body>
</html>
